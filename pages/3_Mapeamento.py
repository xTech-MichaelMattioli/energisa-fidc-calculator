"""
P√°gina de Mapeamento - FIDC Calculator
Mapeamento autom√°tico e manual de campos dos arquivos
"""

import streamlit as st
import pandas as pd
from utils.mapeador_campos import MapeadorCampos

def show():
    """P√°gina de Mapeamento de Campos"""
    st.header("üó∫Ô∏è MAPEAMENTO DE CAMPOS")
    
    # Verificar se h√° arquivos carregados
    if 'df_carregado' not in st.session_state or not st.session_state.df_carregado:
        st.warning("‚ö†Ô∏è Carregue um ou mais arquivos antes de prosseguir para o mapeamento.")
        st.info("üí° V√° para a p√°gina de **Carregamento** e fa√ßa upload dos arquivos Excel primeiro.")
        return
    
    # Verificar se os par√¢metros est√£o inicializados
    if 'params' not in st.session_state:
        from utils.parametros_correcao import ParametrosCorrecao
        st.session_state.params = ParametrosCorrecao()
    
    arquivos_processados = st.session_state.df_carregado
    mapeador = MapeadorCampos(st.session_state.params)
    
    st.write("Mapeie as colunas dos arquivos para os campos padr√£o do sistema.")
    
    # Informa√ß√µes gerais
    total_arquivos = len(arquivos_processados)
    total_registros = sum(info['registros'] for info in arquivos_processados.values())
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("üìÅ Arquivos para Mapear", total_arquivos)
    with col2:
        # Verificar se j√° temos mapeamentos salvos
        mapeamentos_salvos = 0
        if 'mapeamentos_finais' in st.session_state:
            mapeamentos_salvos = len(st.session_state.mapeamentos_finais)
        st.metric("‚úÖ Mapeamentos Salvos", f"{mapeamentos_salvos}/{total_arquivos}")
    with col3:
        st.metric("üìä Total de Registros", f"{total_registros:,}")
    
    st.markdown("---")
    
    # Inicializar estado dos mapeamentos
    if 'mapeamentos_finais' not in st.session_state:
        st.session_state.mapeamentos_finais = {}
    
    # Processar cada arquivo individualmente
    for nome_arquivo, info_arquivo in arquivos_processados.items():
        st.subheader(f"üìÑ Mapeamento: {nome_arquivo}")
        
        df_arquivo = info_arquivo['dataframe']
        
        # Informa√ß√µes do arquivo
        col1, col2 = st.columns(2)
        with col1:
            st.info(f"üìä **Registros:** {len(df_arquivo):,}")
        with col2:
            st.info(f"üìã **Colunas:** {len(df_arquivo.columns)}")
        
        # Mostrar estrutura do arquivo
        with st.expander(f"üìã Ver estrutura de {nome_arquivo}", expanded=False):
            st.dataframe(df_arquivo.head(3), use_container_width=True)
            
            # Mostrar todas as colunas
            st.write("**üìã Lista de Colunas:**")
            colunas_formatadas = [f"‚Ä¢ {col}" for col in df_arquivo.columns]
            st.write("\n".join(colunas_formatadas[:15]))  # Mostrar primeiras 15
            if len(df_arquivo.columns) > 15:
                st.caption(f"... e mais {len(df_arquivo.columns) - 15} colunas")
        
        # Mapeamento autom√°tico para este arquivo
        try:
            with st.spinner(f"üîç Analisando colunas de {nome_arquivo}..."):
                mapeamento_auto = mapeador.criar_mapeamento_automatico(df_arquivo, nome_arquivo)
        except Exception as e:
            st.error(f"‚ùå Erro no mapeamento autom√°tico de {nome_arquivo}: {str(e)}")
            mapeamento_auto = {}
        
        # Usar mapeamento salvo se existir, sen√£o usar o autom√°tico
        if nome_arquivo in st.session_state.mapeamentos_finais:
            mapeamento_inicial = st.session_state.mapeamentos_finais[nome_arquivo]
        else:
            mapeamento_inicial = mapeamento_auto if mapeamento_auto else {}
        
        try:
            mapeamento_manual = mapeador.permitir_mapeamento_manual(
                df_arquivo, 
                mapeamento_inicial,
                nome_arquivo,  # Passar nome do arquivo para detec√ß√£o VOLTZ
                key_suffix=f"_{nome_arquivo.replace('.', '_').replace(' ', '_')}"
            )
            
            # Bot√µes de a√ß√£o para este arquivo
            col1, col2 = st.columns(2)
            
            with col1:
                if st.button(f"üíæ Salvar Mapeamento", key=f"salvar_{nome_arquivo}", type="secondary"):
                    st.session_state.mapeamentos_finais[nome_arquivo] = mapeamento_manual
                    st.success(f"‚úÖ Mapeamento salvo para {nome_arquivo}!")
                    st.rerun()
            
            with col2:
                # Verificar se o mapeamento est√° salvo
                if nome_arquivo in st.session_state.mapeamentos_finais:
                    st.success("‚úÖ Mapeamento salvo")
                else:
                    st.warning("‚è≥ Mapeamento n√£o salvo")
        
        except Exception as e:
            st.error(f"‚ùå Erro no mapeamento manual de {nome_arquivo}: {str(e)}")
        
        st.markdown("---")
    
    # Aplicar todos os mapeamentos
    st.subheader("üîÑ Aplicar Todos os Mapeamentos")
    
    # Verificar quantos mapeamentos est√£o salvos
    mapeamentos_salvos = len(st.session_state.mapeamentos_finais)
    
    if mapeamentos_salvos == 0:
        st.warning("‚ö†Ô∏è Nenhum mapeamento foi salvo ainda.")
    elif mapeamentos_salvos < total_arquivos:
        st.warning(f"‚ö†Ô∏è Apenas {mapeamentos_salvos} de {total_arquivos} mapeamentos foram salvos.")
    else:
        st.success(f"‚úÖ Todos os {total_arquivos} mapeamentos foram salvos!")
    
    # Bot√£o para aplicar todos os mapeamentos
    if st.button("üöÄ Aplicar Todos os Mapeamentos", type="primary", key="aplicar_todos_mapeamentos"):
        if not st.session_state.mapeamentos_finais:
            st.error("‚ùå Nenhum mapeamento foi salvo. Salve pelo menos um mapeamento antes de prosseguir.")
            return
        
        with st.spinner("üîÑ Aplicando mapeamentos e padronizando dados..."):
            try:
                # Dicion√°rio para armazenar os dataframes padronizados
                dataframes_padronizados = {}
                total_registros_processados = 0
                
                for nome_arquivo, mapeamento_final in st.session_state.mapeamentos_finais.items():
                    if nome_arquivo in arquivos_processados:
                        df_arquivo = arquivos_processados[nome_arquivo]['dataframe']
                        
                        # Aplicar mapeamento
                        df_padronizado = mapeador.aplicar_mapeamento(df_arquivo, mapeamento_final, nome_arquivo)
                        
                        if not df_padronizado.empty:
                            dataframes_padronizados[nome_arquivo] = df_padronizado
                            total_registros_processados += len(df_padronizado)
                            st.success(f"‚úÖ {nome_arquivo}: {len(df_padronizado):,} registros padronizados")
                        else:
                            st.error(f"‚ùå Erro ao aplicar mapeamento em {nome_arquivo}")
                
                if dataframes_padronizados:
                    # Combinar todos os dataframes padronizados
                    if len(dataframes_padronizados) == 1:
                        # Apenas um arquivo
                        df_final_padronizado = list(dataframes_padronizados.values())[0]
                        nome_arquivo_unico = list(dataframes_padronizados.keys())[0]
                    else:
                        # M√∫ltiplos arquivos - combinar
                        df_final_padronizado = pd.concat(
                            dataframes_padronizados.values(), 
                            ignore_index=True
                        )
                        nome_arquivo_unico = None
                    
                    # ========== VERIFICA√á√ÉO DE DUPLICATAS ESPEC√çFICA PARA VOLTZ ==========
                    st.info("üîç Verificando duplicatas...")
                    
                    # Detectar se √© VOLTZ
                    eh_voltz = False
                    if nome_arquivo_unico:
                        # Um √∫nico arquivo - verificar se √© VOLTZ
                        eh_voltz = 'VOLTZ' in nome_arquivo_unico.upper()
                    else:
                        # M√∫ltiplos arquivos - verificar se algum √© VOLTZ
                        eh_voltz = any('VOLTZ' in nome.upper() for nome in dataframes_padronizados.keys())
                    
                    registros_antes = len(df_final_padronizado)
                    
                    if eh_voltz:
                        st.info("‚ö° **VOLTZ detectado** - Usando crit√©rio espec√≠fico: nome + data_vencimento + documento")
                        
                        # Verificar se temos as colunas necess√°rias para VOLTZ
                        colunas_voltz = ['nome_cliente', 'data_vencimento', 'documento']
                        colunas_disponiveis = [col for col in colunas_voltz if col in df_final_padronizado.columns]
                        
                        if len(colunas_disponiveis) >= 2:  # Pelo menos 2 das 3 colunas
                            # Criar chave de duplicata usando as colunas dispon√≠veis
                            colunas_para_duplicata = []
                            
                            if 'nome_cliente' in df_final_padronizado.columns:
                                colunas_para_duplicata.append('nome_cliente')
                                # Limpar e padronizar nome de forma mais rigorosa para VOLTZ
                                df_final_padronizado['nome_cliente_limpo'] = (
                                    df_final_padronizado['nome_cliente']
                                    .astype(str)
                                    .str.strip()
                                    .str.upper()
                                    .str.replace(r'\s+', ' ', regex=True)
                                    .str.replace(r'[^\w\s]', '', regex=True)  # Remove pontua√ß√£o
                                    .str.replace(r'\b(LTDA|S\.?A\.?|ME|EPP|EIRELI)\b', '', regex=True)  # Remove sufixos empresariais
                                    .str.strip()
                                )
                                colunas_para_duplicata.append('nome_cliente_limpo')
                            
                            if 'data_vencimento' in df_final_padronizado.columns:
                                # Padronizar data de vencimento
                                df_final_padronizado['data_vencimento_limpa'] = pd.to_datetime(
                                    df_final_padronizado['data_vencimento'], 
                                    errors='coerce'
                                ).dt.date
                                colunas_para_duplicata.append('data_vencimento_limpa')
                            
                            if 'documento' in df_final_padronizado.columns:
                                # Limpar e padronizar documento (CPF/CNPJ)
                                df_final_padronizado['documento_limpo'] = (
                                    df_final_padronizado['documento']
                                    .astype(str)
                                    .str.replace(r'[^\d]', '', regex=True)
                                    .str.strip()
                                )
                                colunas_para_duplicata.append('documento_limpo')
                            
                            # Usar apenas as colunas relevantes (remover as auxiliares do subset)
                            subset_final = ['nome_cliente_limpo'] if 'nome_cliente_limpo' in colunas_para_duplicata else []
                            if 'data_vencimento_limpa' in colunas_para_duplicata:
                                subset_final.append('data_vencimento_limpa')
                            if 'documento_limpo' in colunas_para_duplicata:
                                subset_final.append('documento_limpo')
                            
                            if subset_final:
                                # VOLTZ: N√£o remover duplicatas - manter todos os registros
                                # Apenas limpar colunas auxiliares
                                colunas_auxiliares = ['nome_cliente_limpo', 'data_vencimento_limpa', 'documento_limpo']
                                df_final_padronizado = df_final_padronizado.drop(
                                    columns=[col for col in colunas_auxiliares if col in df_final_padronizado.columns]
                                )
                                
                                st.success("‚úÖ **VOLTZ**: Todos os registros mantidos (duplicatas n√£o removidas)")
                            else:
                                st.warning("‚ö†Ô∏è **VOLTZ**: Colunas necess√°rias n√£o encontradas para verifica√ß√£o de duplicatas")
                        else:
                            st.warning(f"‚ö†Ô∏è **VOLTZ**: Apenas {len(colunas_disponiveis)} de 3 colunas necess√°rias encontradas: {colunas_disponiveis}")
                    else:
                        st.info("üìä **Distribuidora padr√£o** - Usando crit√©rio padr√£o de duplicatas")
                        
                        # Verifica√ß√£o padr√£o de duplicatas para outras distribuidoras
                        # Usar crit√©rio mais abrangente: nome + valor_principal + data_vencimento
                        colunas_padrao = []
                        
                        if 'nome_cliente' in df_final_padronizado.columns:
                            df_final_padronizado['nome_cliente_limpo'] = (
                                df_final_padronizado['nome_cliente']
                                .astype(str).str.strip().str.upper()
                            )
                            colunas_padrao.append('nome_cliente_limpo')
                        
                        if 'valor_principal' in df_final_padronizado.columns:
                            colunas_padrao.append('valor_principal')
                        
                        if 'data_vencimento' in df_final_padronizado.columns:
                            df_final_padronizado['data_vencimento_limpa'] = pd.to_datetime(
                                df_final_padronizado['data_vencimento'], 
                                errors='coerce'
                            ).dt.date
                            colunas_padrao.append('data_vencimento_limpa')
                        
                        if len(colunas_padrao) >= 2:
                            df_final_padronizado = df_final_padronizado.drop_duplicates(
                                subset=colunas_padrao, 
                                keep='first'
                            ).reset_index(drop=True)
                            
                            # Limpar colunas auxiliares
                            colunas_auxiliares = ['nome_cliente_limpo', 'data_vencimento_limpa']
                            df_final_padronizado = df_final_padronizado.drop(
                                columns=[col for col in colunas_auxiliares if col in df_final_padronizado.columns]
                            )
                            
                            registros_depois = len(df_final_padronizado)
                            duplicatas_removidas = registros_antes - registros_depois
                            
                            if duplicatas_removidas > 0:
                                st.warning(f"‚ö†Ô∏è **Padr√£o**: {duplicatas_removidas:,} duplicatas removidas")
                            else:
                                st.success("‚úÖ **Padr√£o**: Nenhuma duplicata encontrada")
                        else:
                            st.info("‚ÑπÔ∏è Verifica√ß√£o de duplicatas n√£o aplicada - colunas insuficientes")
                    
                    # Salvar resultado
                    st.session_state.df_padronizado = df_final_padronizado
                    st.session_state.dataframes_individuais = dataframes_padronizados
                    
                    st.success(f"üéØ **Mapeamento e verifica√ß√£o de duplicatas conclu√≠dos!** {len(df_final_padronizado):,} registros finais de {len(dataframes_padronizados)} arquivo(s)")
                    
                    if registros_antes != len(df_final_padronizado):
                        duplicatas_removidas = registros_antes - len(df_final_padronizado)
                        st.info(f"üìä Registros processados: {registros_antes:,} ‚Üí {len(df_final_padronizado):,} (removidas {duplicatas_removidas:,} duplicatas)")
                    
                    # Mostrar preview do resultado final
                    st.subheader("üìä Preview dos Dados Padronizados Consolidados")
                    
                    # M√©tricas do resultado
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("üìä Total de Registros", f"{len(df_final_padronizado):,}")
                    with col2:
                        st.metric("üìÅ Arquivos Processados", len(dataframes_padronizados))
                    with col3:
                        # Verificar campos essenciais no resultado final
                        campos_obrigatorios = ['empresa', 'tipo', 'status', 'situacao', 'nome_cliente', 'classe', 'contrato', 'valor_principal', 'valor_nao_cedido', 'valor_terceiro', 'valor_cip', 'data_vencimento']
                        campos_ok = sum(1 for campo in campos_obrigatorios if campo in df_final_padronizado.columns)
                        st.metric("‚úÖ Campos Obrigat√≥rios", f"{campos_ok}/{len(campos_obrigatorios)}")
                    
                    # Preview da tabela consolidada
                    st.dataframe(df_final_padronizado.head(10), use_container_width=True)
                    
                    # Valida√ß√£o final considerando VOLTZ
                    problemas = []
                    campos_obrigatorios_validacao = ['empresa', 'tipo', 'status', 'situacao', 'nome_cliente', 'classe', 'contrato', 'valor_principal', 'valor_nao_cedido', 'valor_terceiro', 'valor_cip', 'data_vencimento']
                    
                    # Verificar se algum arquivo √© VOLTZ para ajustar valida√ß√£o
                    tem_voltz = False
                    campos_automaticos_voltz = []
                    if hasattr(mapeador, 'identificar_tipo_distribuidora'):
                        for nome_arquivo in arquivos_processados.keys():
                            if mapeador.identificar_tipo_distribuidora(nome_arquivo) == "VOLTZ":
                                tem_voltz = True
                                campos_automaticos_voltz = ['empresa', 'valor_nao_cedido', 'valor_terceiro', 'valor_cip']
                                break
                    
                    for campo in campos_obrigatorios_validacao:
                        if campo not in df_final_padronizado.columns:
                            # Para VOLTZ, alguns campos s√£o adicionados automaticamente
                            if campo in campos_automaticos_voltz and tem_voltz:
                                continue
                            problemas.append(f"‚ùå Campo {campo.replace('_', ' ').title()} n√£o identificado")
                    
                    if problemas:
                        st.warning("‚ö†Ô∏è **Aten√ß√£o:** Alguns campos obrigat√≥rios n√£o foram identificados:")
                        for problema in problemas:
                            st.write(problema)
                        st.write("Revise os mapeamentos antes de prosseguir.")
                    else:
                        st.success("üéØ **Perfeito!** Todos os campos obrigat√≥rios foram identificados corretamente.")
                        
                        # Mostrar pr√≥ximo passo
                        st.info("‚ú® **Pr√≥ximo passo:** V√° para a p√°gina de **Corre√ß√£o** para calcular os valores corrigidos.")
                else:
                    st.error("‚ùå Nenhum arquivo foi processado com sucesso. Verifique os mapeamentos.")
                    
            except Exception as e:
                st.error(f"‚ùå Erro ao aplicar mapeamentos: {str(e)}")
    
    # Status do mapeamento geral
    if 'df_padronizado' in st.session_state and not st.session_state.df_padronizado.empty:
        st.markdown("---")
        st.success(f"‚úÖ **Mapeamento conclu√≠do:** {len(st.session_state.df_padronizado):,} registros padronizados de {len(st.session_state.get('dataframes_individuais', {})):,} arquivo(s)")
        
        # Resumo dos campos mapeados
        st.subheader("üìã Resumo dos Campos Mapeados")
        
        df_padronizado = st.session_state.df_padronizado
        campos_mapeados = list(df_padronizado.columns)
        
        # Agrupar campos por categoria
        campos_principais = [col for col in campos_mapeados if col in ['empresa', 'tipo', 'status', 'situacao', 'nome_cliente', 'classe', 'contrato']]
        campos_valores = [col for col in campos_mapeados if 'valor' in col.lower()]
        campos_datas = [col for col in campos_mapeados if 'data' in col.lower()]
        campos_outros = [col for col in campos_mapeados if col not in campos_principais + campos_valores + campos_datas]
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.write("**üë• Campos Principais:**")
            for campo in campos_principais:
                st.write(f"‚Ä¢ {campo}")
        
        with col2:
            st.write("**üí∞ Campos de Valor:**")
            for campo in campos_valores:
                st.write(f"‚Ä¢ {campo}")
        
        with col3:
            st.write("**üìÖ Campos de Data:**")
            for campo in campos_datas:
                st.write(f"‚Ä¢ {campo}")
        
        with col4:
            st.write("**üìã Outros Campos:**")
            for campo in campos_outros[:5]:  # Limitar para n√£o poluir
                st.write(f"‚Ä¢ {campo}")
            if len(campos_outros) > 5:
                st.caption(f"... e mais {len(campos_outros) - 5} campos")
    
    # Informa√ß√µes sobre o mapeamento
    st.markdown("---")
    st.subheader("‚ÑπÔ∏è Informa√ß√µes sobre Mapeamento")
    
    with st.expander("üó∫Ô∏è Como funciona o Mapeamento Autom√°tico", expanded=False):
        st.info("""
        **Processo autom√°tico:**
        1. **An√°lise das colunas:** O sistema analisa os nomes das colunas
        2. **Correspond√™ncia por palavras-chave:** Busca por termos como "empresa", "valor", "data", etc.
        3. **Valida√ß√£o de conte√∫do:** Verifica se o tipo de dados corresponde ao esperado
        4. **Sugest√£o de mapeamento:** Prop√µe o melhor mapeamento encontrado
        
        **Campos obrigat√≥rios:**
        - Empresa/Distribuidora
        - Tipo de cliente
        - Status da conta
        - Nome do cliente
        - Valor principal
        - Data de vencimento
        
        **Campos opcionais mas importantes:**
        - Valor n√£o cedido
        - Valor terceiro
        - Valor CIP
        - Classe do cliente
        - Contrato/Conta
        """)
    
    with st.expander("‚úèÔ∏è Mapeamento Manual", expanded=False):
        st.info("""
        **Quando usar:**
        - Mapeamento autom√°tico n√£o encontrou correspond√™ncia
        - Nomes de colunas n√£o padronizados
        - Estrutura de arquivo diferente do padr√£o
        
        **Como funciona:**
        - Selecione a coluna correta para cada campo
        - Op√ß√£o "-- N√£o dispon√≠vel --" para campos inexistentes
        - Valida√ß√£o em tempo real dos tipos de dados
        - Possibilidade de ajustar mapeamentos autom√°ticos
        
        **Dicas:**
        - Sempre valide o preview ap√≥s o mapeamento
        - Campos obrigat√≥rios devem ser mapeados
        - Salve cada mapeamento antes de prosseguir
        """)

if __name__ == "__main__":
    show()
